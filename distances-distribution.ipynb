{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9672725d",
   "metadata": {},
   "source": [
    "KL-Divergence:\n",
    "If two distributions perfectly match, D_{KL} (p||q) = 0 otherwise it can take values between 0 and ∞. Lower the KL divergence value, the better we have matched the true distribution with our approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35820164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, mannwhitneyu, chisquare, wasserstein_distance\n",
    "from statsmodels.stats import weightstats as stests\n",
    "from scipy.spatial.distance import cityblock\n",
    "from matplotlib import pyplot as plt \n",
    "from scipy.spatial import distance\n",
    "from scipy.special import kl_div,rel_entr\n",
    "from os.path import isfile, join\n",
    "from scipy.stats import entropy\n",
    "from os import listdir\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e461f9",
   "metadata": {},
   "source": [
    "# Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34661d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = ['twitter', 'uwcse', 'imdb', 'cora']\n",
    "targets = ['imdb', 'cora', 'uwcse', 'twitter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a43a3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df25af",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_kde(source_distribution, source_name, target_distribution, target_name):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    if(len(source_distribution) != len(target_distribution)):\n",
    "        source_distribution, target_distribution = shape_arrays_to_same_length(source_distribution, target_distribution)\n",
    "        \n",
    "    sns.kdeplot(data=np.array(source_distribution).cumsum(),\n",
    "                color='crimson', label=source_name.upper(), fill=True, ax=ax)\n",
    "    sns.kdeplot(data=np.array(target_distribution).cumsum(),\n",
    "                color='limegreen', label=target_name.upper(), fill=True, ax=ax)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.title(f'{source_name.upper()} -> {target_name.upper()}')\n",
    "    #fig.savefig(f'figures/kde/{source_name}/kde_{source_name}_{target_name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124a1c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_histogram(source_distribution, source_name, target_distribution, target_name):\n",
    "    bins = np.linspace(0, 1, 10)\n",
    "\n",
    "    if(len(source_distribution) != len(target_distribution)):\n",
    "        source_distribution, target_distribution = shape_arrays_to_same_length(source_distribution, target_distribution)\n",
    "    \n",
    "    plt.hist(source_distribution, bins, alpha=0.5, label=source_name.upper())\n",
    "    plt.hist(target_distribution, bins, alpha=0.5, label=target_name.upper())\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'{source_name.upper()} -> {target_name.upper()}')\n",
    "    #plt.savefig(f'figures/hist/{target_name}/hist_{source_name}_{target_name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15901b77",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73d124c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def use_histograms(array1,array2):\n",
    "    if len(array1) > len(array2):\n",
    "        n_bins = round(np.sqrt(len(array2)))\n",
    "    else:\n",
    "        n_bins = round(np.sqrt(len(array1)))\n",
    "    return np.histogram(array1,bins=n_bins)[0],np.histogram(array2,bins=n_bins)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438adb5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def shape_arrays_to_same_length_dumb_way(array1, array2):\n",
    "    size_array_1 = len(array1)\n",
    "    size_array_2 = len(array2)\n",
    "    np.random.shuffle(array1)\n",
    "    np.random.shuffle(array2)\n",
    "    if(size_array_1 > size_array_2):\n",
    "        return array1[:size_array_2], array2\n",
    "    elif(size_array_1 < size_array_2):\n",
    "        return array1, array2[:size_array_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e568d99d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def shape_arrays_to_same_length_truncate(array1, array2):\n",
    "    size_array_1 = len(array1)\n",
    "    size_array_2 = len(array2)\n",
    "    if(size_array_1 > size_array_2):\n",
    "        np.random.shuffle(array2)\n",
    "        return np.random.choice(array1, size_array_2), array2\n",
    "    elif(size_array_1 < size_array_2):\n",
    "        np.random.shuffle(array1)\n",
    "        return array1, np.random.choice(array2, size_array_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdaa6d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def shape_arrays_to_same_length(array1, array2):\n",
    "    size_array_1 = len(array1)\n",
    "    size_array_2 = len(array2)\n",
    "    if(size_array_1 > size_array_2):\n",
    "        return array1, np.concatenate((array2,np.zeros(size_array_1-size_array_2)))\n",
    "    elif(size_array_1 < size_array_2):\n",
    "        return np.concatenate((array1,np.zeros(size_array_2-size_array_1))), array2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b614e012",
   "metadata": {},
   "source": [
    "## Probabilities Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587dbe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_probabilities_array(sample):\n",
    "    prob, class_ = sample.split(' ')\n",
    "    prob = float(prob.strip())\n",
    "    class_ = class_.strip()\n",
    "    \n",
    "    if class_ == '0':\n",
    "        return [prob, 1-prob][1]\n",
    "    elif class_ == '1':\n",
    "        return [1-prob, prob][1]\n",
    "    else:\n",
    "        raise Exception(\"Error --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b30e3",
   "metadata": {},
   "source": [
    "## Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d11020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source_distribution(path,fold=0):\n",
    "    \n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    files = [f'aucTemp_{fold+1}']\n",
    "    \n",
    "    N_FOLDS = len(files)\n",
    "    source_name = path.split('/')[-1].upper()\n",
    "    #print(f'load_source_distribution: {source_name} has {N_FOLDS} folds.')\n",
    "    \n",
    "    if source_name == 'TWITTER' and fold > 1:\n",
    "        files = ['aucTemp_1']\n",
    "\n",
    "    source_distribution = []\n",
    "    for file in files:\n",
    "        test = open(path + '/' + file, 'r').read().split('\\n')\n",
    "        \n",
    "        #print(f'load_source_distribution: {file} has {len(test)} examples.')\n",
    "\n",
    "        if test[-1] == '':\n",
    "            del test[-1]\n",
    "        \n",
    "        #if source_distribution.size == 0:\n",
    "        #    source_distribution = np.zeros(len(test))\n",
    "\n",
    "        source_distribution = source_distribution + [generate_probabilities_array(test[i]) for i in range(len(test))]\n",
    "\n",
    "    #source_distribution /= N_FOLDS\n",
    "    return np.array(source_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3cd6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_features(path):\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    \n",
    "    for file in files:\n",
    "        if '.npz' in file:\n",
    "            test = np.load(path + '/' + file)\n",
    "            return np.matrix(test['examples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697f039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_target_distribution(path, fold=0):\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    \n",
    "    if '.json' in files[0]:\n",
    "        test = np.load(path + '/' + files[1])\n",
    "    else:\n",
    "        test = np.load(path + '/' + files[0])\n",
    "            \n",
    "    #target_name = path.split('/')[-1].upper()\n",
    "    #print(f'load_target_distribution: {target_name} has {N_FOLDS} folds.')\n",
    "    \n",
    "    N_EXAMPLES = len(test['proba'][fold])\n",
    "    target_distribution = [test['proba'][fold][i][1] for i in range(N_EXAMPLES)]\n",
    "    \n",
    "    return np.array(target_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6cf0f4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Smoothing and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb476f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def lidstone_smoothing(samples,alpha):\n",
    "    # P(x’/positive)= (number of reviews with x’ and target_outcome=positive + α) / (N + α*k)\n",
    "    # alpha(α) represents the smoothing parameter,\n",
    "    # K represents the dimensions(no of features) in the data,\n",
    "    # N represents the number of reviews with target_outcome=positive\n",
    "    \n",
    "    D = dict()\n",
    "    \n",
    "    train_unique_feature_values = training_data[training_data['label'] == category][column_name].unique()\n",
    "    \n",
    "    data_unique_feature_values = data[column_name].unique()\n",
    "    \n",
    "    for feature_value in data_unique_feature_values:\n",
    "        \n",
    "        if feature_value not in train_unique_feature_values:\n",
    "            \n",
    "            D[feature_value] = alpha/(training_data[training_data['label'] == category].shape[0] + (data_unique_feature_values.shape[0]*alpha))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            D[feature_value] = np.count_nonzero(training_data[training_data['label'] == category][column_name] == feature_value)/training_data[training_data['label'] == category].shape[0]\n",
    "            \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c07202",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#def laplace_smoothing(samples,alpha):\n",
    "    \n",
    "#    for sample in samples:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5dad25",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def kl_divergence(p,q):\n",
    "    current = []\n",
    "    for i,j in zip(p,q):\n",
    "        #log_pq = np.exp(p/q)\n",
    "        if (np.log(i/j)) == 0:\n",
    "        #if (np.exp(p/q)).all() == 0:\n",
    "            log_pq = 0\n",
    "            continue\n",
    "        else:\n",
    "            log_pq = np.log(i/j)\n",
    "            #log_pq = np.exp(p/q)\n",
    "        current.append(i*log_pq)\n",
    "    return np.sum(np.array(current))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45648765",
   "metadata": {},
   "source": [
    "# Calculate Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84f6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probabilities(fold):\n",
    "    results = {}\n",
    "    distributions = {}\n",
    "\n",
    "    for target in targets:\n",
    "        for source in sources:\n",
    "            if source == target:\n",
    "                continue\n",
    "            \n",
    "            #print(source, target, fold)\n",
    "            \n",
    "            #if source == 'twitter' and fold > 1:\n",
    "            #    continue\n",
    "\n",
    "            #print(f'Starting experiment {source.upper()} -> {target.upper()}')\n",
    "            experiment = source.upper() + '_' + target.upper()\n",
    "            results[experiment] = {}\n",
    "            #print(f'Experiments for {source.upper()} and {target.upper()}')\n",
    "\n",
    "            #if source.upper() in distributions:\n",
    "            #    source_distribution = distributions['source_' + source.upper()][:]\n",
    "            #else:\n",
    "                # Load source distributions\n",
    "            my_source_path = f'distributions-tests/CLLs/{source}'\n",
    "            source_distribution = load_source_distribution(my_source_path, fold)\n",
    "                #distributions['source_' + source.upper()] = source_distribution[:]\n",
    "\n",
    "            #print(f'{source.upper()} has {len(source_distribution)} examples.')\n",
    "\n",
    "            #if target.upper() in distributions:\n",
    "            #    target_distribution = distributions['target_' + target.upper()][:]\n",
    "            #else:\n",
    "                # Load target distributions\n",
    "            my_target_path = f'logs/{target}'\n",
    "            target_distribution = load_target_distribution(my_target_path, fold)\n",
    "                #distributions['target_' + target.upper()] = target_distribution[:]\n",
    "\n",
    "            #print(f'{target.upper()} has {len(target_distribution)} examples.')\n",
    "\n",
    "            if(len(source_distribution) != len(target_distribution)):\n",
    "                #source_distribution, target_distribution = shape_arrays_to_same_length_dumb_way(source_distribution, target_distribution)\n",
    "                source_distribution,target_distribution = use_histograms(source_distribution,target_distribution)            \n",
    "            \n",
    "            results[experiment]['JSD'] = distance.jensenshannon(source_distribution,target_distribution)**2\n",
    "            results[experiment]['bckp'] = distance.jensenshannon(source_distribution,target_distribution)\n",
    "            #ztest, propability_value = stests.ztest(source_distribution, target_distribution, value=146)\n",
    "            #results[experiment]['z-test'] = float(propability_value)\n",
    "            #results[experiment]['Euclidean Distance'] = distance.euclidean(source_distribution,target_distribution)\n",
    "            #results[experiment]['Manhattan Distance'] = cityblock(source_distribution,target_distribution)\n",
    "            #results[experiment]['Earth Movers Distance'] = wasserstein_distance(source_distribution, target_distribution)\n",
    "            #stat, p_value = ttest_ind(source_distribution, target_distribution)\n",
    "            #print(f\"{experiment.upper()} -- t-test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "            #stat, p_value = mannwhitneyu(source_distribution, target_distribution)\n",
    "            #print(f\" Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "            #stat, p_value = chisquare(source_distribution, target_distribution)\n",
    "            #print(f\"Chi-squared Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "\n",
    "            #del source_distribution\n",
    "        #del target_distribution\n",
    "    #del distributions\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0d1b3",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29078876",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 5\n",
    "for i in range(N_FOLDS):\n",
    "    results = calculate_probabilities(i)\n",
    "    \n",
    "    if i == 0:\n",
    "        df_add = pd.DataFrame(results)\n",
    "    else:\n",
    "        df_results = pd.DataFrame(results)\n",
    "        df_add = df_add.add(df_results, fill_value = 0)\n",
    "#df_add = df_add/N_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4cf3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add#.sort_values(by=['KL Divergence'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37d2eb6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556ea7c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for source in sources:\n",
    "    for target in targets:\n",
    "        if source == target:\n",
    "            continue\n",
    "        plot_histogram(distributions['source_' + source.upper()], source, distributions['target_' + target.upper()], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969d89e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for source in sources:\n",
    "    for target in targets:\n",
    "        if source == target:\n",
    "            continue\n",
    "        plot_kde(distributions['source_' + source.upper()], source, distributions['target_' + target.upper()], target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2d7e5",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46792ad5",
   "metadata": {},
   "source": [
    "### IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f207d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IMDB = df_add[['CORA_IMDB', 'TWITTER_IMDB', 'UWCSE_IMDB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1fd098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IMDB = df_IMDB/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14117dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  CORA\\_IMDB &  TWITTER\\_IMDB &  UWCSE\\_IMDB \\\\\n",
      "\\midrule\n",
      "JSD  &   0.574002 &      0.257874 &    0.257545 \\\\\n",
      "bckp &   0.757321 &      0.505428 &    0.498705 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-62e4b35eeb60>:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_IMDB.to_latex(index=True))\n"
     ]
    }
   ],
   "source": [
    "print(df_IMDB.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d394fa",
   "metadata": {},
   "source": [
    "### UWCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03f9ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UWCSE = df_add[['CORA_UWCSE', 'IMDB_UWCSE', 'TWITTER_UWCSE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e28dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UWCSE = df_UWCSE / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb16766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  CORA\\_UWCSE &  IMDB\\_UWCSE &  TWITTER\\_UWCSE \\\\\n",
      "\\midrule\n",
      "JSD  &    0.619087 &    0.123431 &       0.179144 \\\\\n",
      "bckp &    0.786714 &    0.350986 &       0.422459 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-620facf7731a>:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_UWCSE.to_latex(index=True))\n"
     ]
    }
   ],
   "source": [
    "print(df_UWCSE.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c405d2d",
   "metadata": {},
   "source": [
    "### Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "443ac769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CORA = df_add[['IMDB_CORA', 'TWITTER_CORA', 'UWCSE_CORA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb241a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CORA = df_CORA / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f35ee008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  IMDB\\_CORA &  TWITTER\\_CORA &  UWCSE\\_CORA \\\\\n",
      "\\midrule\n",
      "JSD  &   0.278352 &      0.337812 &    0.318033 \\\\\n",
      "bckp &   0.527379 &      0.580828 &    0.563612 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-fe7439192ba5>:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_CORA.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(df_CORA.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff28c7",
   "metadata": {},
   "source": [
    "### Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2abc7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TWITTER = df_add[['CORA_TWITTER', 'IMDB_TWITTER', 'UWCSE_TWITTER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69785778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TWITTER = df_TWITTER / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0add20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  CORA\\_TWITTER &  IMDB\\_TWITTER &  UWCSE\\_TWITTER \\\\\n",
      "\\midrule\n",
      "JSD  &      0.655241 &      0.186627 &       0.388452 \\\\\n",
      "bckp &      0.809262 &      0.431531 &       0.615872 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-c376796b4d3e>:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_TWITTER.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(df_TWITTER.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
